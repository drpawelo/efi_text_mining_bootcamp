{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook:\n",
    "\n",
    "1. **Visualising a network of entities**\n",
    "2. Extra other visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Visualising a network of entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell now. It's the usual imports of text mining libraries\n",
    "\n",
    "import nltk\n",
    "import numpy\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's import the needed libraries\n",
    "import nltk\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# from nltk.tag import pos_tag\n",
    "nltk.download('inaugural')\n",
    "from nltk.corpus import inaugural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and some more:\n",
    "!pip install -U spacy #or pip3 if this doesn't work\n",
    "!python3 -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You can use network visualisations to show how things are connected in data.  Networks are often used for showing networks of people in social media.  Today we'll use a network visualisation to display how all US presidents are connected in terms of the people they mention in their speeches.\n",
    "\n",
    "To do that you'll first learn how to save data to a file. The content of file serves as the input to the network. Let's first create the content (```file_content```) which we will write to a file.  We'll be creating a tsv (tab-separated file), meaning that each line contains different fields separated by a tab.  The first line is the header which lists the names for each column.  The first column are the names of presidents and the second column the people mentioned in their speeches.\n",
    "\n",
    "The president/person pairs are created by looping through each speech, extracting the name of each president from the filename of the speech, NER-tagging and extracting people names for each speech.  For all people extracted from each speech, we then concatenate the ```file_content``` variable with the president's name (```president```) and each person name (```person```) mentioned in his speech followed by a newline character (\"\\n\") so that each pair is on one line. The final ```file_content``` contains the header and 102 lines listing all the president/person pairs in this data set.\n",
    "\n",
    "The following code was adapted from Jonathan Soma's tutorial on [NetworkX Graphs](http://jonathansoma.com/lede/algorithms-2017/classes/networks/networkx-graphs-from-source-target-dataframe/). __Note: this first bit of code takes some time to run because each speech has to be tagged individually.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header=\"president\\tperson\\n\"\n",
    "file_content=header\n",
    "for fileid in inaugural.fileids():\n",
    "    president=fileid[5:-4]\n",
    "    #nertagged_words = st.tag(inaugural.words(fileid))\n",
    "    doc = nlp(inaugural.raw(fileid))\n",
    "    named_entities = [(ent.text, ent.label_) for ent in doc.ents] \n",
    "    #named_entities=get_entities(nertagged_words)\n",
    "    people = [string for (string, tag) in named_entities if (tag == 'PERSON') and (not string.startswith('\\n'))]\n",
    "    if len(people) > 0:\n",
    "        for person in people:\n",
    "            file_content=file_content + president + \"\\t\" + person + \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write to a file you need to use the ```open()``` method and specify the file's name and mode (in this case \"w\" for write to file).  You can then use the ```write()``` method and specify the content of the file in brackets.  Don't forget to close the file using ```close()``` once you're done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"presidents.tsv\", \"w\")\n",
    "f.write(file_content)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check that file was created by looking at the Jupyter Notebook homepage in the browser.  The file should now be listed in the same directory as you notebook.\n",
    "\n",
    "We need to import two further packages to visualise a network.  ```pandas``` is used to represent data frames. and ```networkx``` is needed to create a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data frame:__ A data frame is a 2-dimensional labeled data structure with columns of potentially different types.\n",
    "\n",
    "First we create a data frame by reading in the csv file which we just created.  The top of the data frame can be displayed by calling the ```head()``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"presidents.tsv\", sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column in the data frame will serve as the source and the second column as the target in the network.  We can create a simple network specifying source and target using the headers of the columns in the data frame.\n",
    "\n",
    "__Node:__ A network node is a connection point.\n",
    "\n",
    "__Edge:__ A network edge is a connection between two nodes. \n",
    "\n",
    "This initial network isn't very informative yet as you can't see who each node (blue circles) refers to.  So next we need to make it more pretty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.from_pandas_edgelist(df, source='president', target='person') \n",
    "nx.draw(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to create a list of all presidents by extracting their names from the data frame and removing repetitions. Note, these are only presidents whose speeches contain person names tagged by the NER tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presidents = list(df.president.unique())\n",
    "presidents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do the same for the names of people recognised in the speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = list(df.person.unique())\n",
    "people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The degree of a node in a network is the number of connections it has to other nodes.  For example, the degree for \"Reagan\" can be calculated using the ```degree()``` method on initial network.  We will use degree as a way of varying the node size of person nodes, people with a larger degree will be displayed bigger in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.degree(\"Reagan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following bit of code draws the network. The first two lines set the size of the graph and the layout of the network.  \n",
    "\n",
    "After that the different nodes are drawn using differnt parameters for node_color and node_size.  Then the edges and node labels are drawn and the title of the network is specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the size of the network\n",
    "plt.figure(figsize=(30, 30))\n",
    "\n",
    "# you can choose different ways of laying out the network\n",
    "layout = nx.spring_layout(g)\n",
    "\n",
    "# go through every person name, ask the graph how many\n",
    "# connections it has. Multiply that by 100 to get the circle size\n",
    "person_size = [g.degree(person) * 100 for person in people]\n",
    "\n",
    "# draw the people nodes\n",
    "nx.draw_networkx_nodes(g, \n",
    "                       layout, \n",
    "                       nodelist=people,\n",
    "                       node_color='lightblue',\n",
    "                       node_size=person_size # a list of sizes, based on g.degree\n",
    "                       )\n",
    "\n",
    "# draw president nodes\n",
    "nx.draw_networkx_nodes(g, layout, nodelist=presidents, node_color='wheat', node_size=100)\n",
    "\n",
    "# popular presidents are ones which had more than one presidency\n",
    "popular_president = [president for president in presidents if g.degree(president) > 0 ]\n",
    "\n",
    "# draw popular president nodes\n",
    "nx.draw_networkx_nodes(g, layout, nodelist=popular_president, node_color='orange', node_size=100)\n",
    "\n",
    "# draw network edges\n",
    "nx.draw_networkx_edges(g, layout, width=1, edge_color=\"#cccccc\")\n",
    "\n",
    "# draw node labels\n",
    "nx.draw_networkx_labels(g, layout, font_size=12)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.title(\"Presidents and people\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🐛Minitask: \n",
    "\n",
    "copy-paste the code of above visualisation into below cell and try to customise it with your buddy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another interesting visualisation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at entities analysis and highlighting.\n",
    "\n",
    "`displacy.render(doc, style=\"ent\",jupyter=True)`  would visualise the text with the entities highlighted.\n",
    "\n",
    "and \n",
    "\n",
    "`displacy.render(doc, style=\"dep\",jupyter=True)`  would visualise the text with dependencies of words, but as a method of visualisation it works best for short sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "text = \"When Sebastian Thrun started working on self-driving cars at Google in 2007, \"\n",
    "text += \"few people outside of the company took him seriously. Not it changed the Unided States and the world\"\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style=\"dep\",jupyter=True)\n",
    "\n",
    "#this image will be very wide, so you'll need to scroll sideways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A method more interesting to us at this point is the highlighting of entities. Let's look at it first using our small example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc, style=\"ent\",jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highlighting entities is a completly new area that you could go and explore: \n",
    "\n",
    "here is a list of token types, for more details browse https://spacy.io/models/en and look at label scheme\n",
    "\n",
    "```\n",
    "NER: \n",
    "CARDINAL, DATE, EVENT, FAC, GPE, LANGUAGE, LAW, LOC, MONEY, NORP, ORDINAL, ORG, PERCENT, PERSON, PRODUCT, QUANTITY, TIME, WORK_OF_ART\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example with speeches of President Obama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "corpus_root = \"./data/barack_obama_speeches\"\n",
    "corpus_data = PlaintextCorpusReader(corpus_root, '.*', encoding='latin1') \n",
    "plain_text = corpus_data.raw()[:2000] # take first 2000 characters\n",
    "doc = nlp(plain_text)\n",
    "displacy.render(doc, style=\"ent\",jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
